<!DOCTYPE html><meta charset='UTF-8'><html><head><link rel='stylesheet' href='katex/katex.min.css'    integrity='sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X'    crossorigin='anonymous'><!-- The loading of KaTeX is deferred to speed up page rendering --><script defer src='katex/katex.min.js'    integrity='sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4'    crossorigin='anonymous'></script><script>    function on_katex_load() {        const katex_opts = [            {left: '$', right: '$', display: false},            {left: '$$', right: '$$', display: true}        ];        renderMathInElement(document.body, katex_opts);        let elemsInline = document.getElementsByClassName('latexinline');        for (var i = 0; i < elemsInline.length; i++) {katex.render(elemsInline.item(i).textContent, elemsInline.item(i));}        let elemsBlock = document.getElementsByClassName('latexblock');        for (var i = 0; i < elemsInline.length; i++) {katex.render(elemsBlock.item(i).textContent, elemsBlock.item(i), {displayMode: true});}    }</script><!-- To automatically render math in text elements, include the auto-render extension: --><script defer src='katex/auto-render.min.js'    integrity='sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa'    crossorigin='anonymous'    onload='on_katex_load();'></script><title> A Universe of Sorts </title><style>@font-face {font-family: 'Blog Mono'; src: url('/static/iosevka-etoile-fixed.ttf');}@font-face {font-family: 'Blog Symbol'; src: url('/static/Symbola.ttf');}@font-face {font-family: 'Blog Text'; src: url('/static/Exo2-Regular.ttf');}html { font-size: 100%; }html,body { text-size-adjust: none; -webkit-text-size-adjust: none; -moz-text-size-adjust: none; -ms-text-size-adjust: none; } body { background-color: #FFFFFF; color: #000000;  font-family: 'Blog Text', sans-serif; font-size: 18px; line-height: 1.4em;  max-width: 100%; }
img { display:block; }.container { overflow-x: hidden }@media (max-width: 480px) { .container { margin-left: 5%; margin-right: 2%; } body { font-size: 40px; } }@media (max-width: 1024px) { .container { margin-left: 5%; margin-right: 2%; } body { font-size: 40px; } }@media (min-width: 1024px) { .container { margin-left: 30%; margin-right: 25%; } }.image { }
a:hover { color: #1a73e8; text-decoration: underline;  }
a { color: #1a73e8; text-decoration: none; }
a:visited { color: #1a73e8; text-decoration: none; }
a:active { color: #1a73e8; text-decoration: none; }

 .code, .latexblock, blockquote { border-left-color:#BBB;  border-left-style: solid;      border-left-width: 1px; }.code pre, blockquote { padding-left: 10px; }
 .code { font-family: 'Blog Mono', monospace; font-size: 90%;  }.latexblock, blockquote, .code, code { margin-top: 10px; margin-bottom: 10px; padding-bottom: 5px; padding-top: 5px; background-color: #FFFFFF; }.code, code { background-color: #FFFFFF; width: 100%; }.latexblock { line-height: 1em } .latexblock {  width: 100%; overflow-x: auto; white-space: nowrap; } .code pre { width: 100%; overflow-x: auto; margin: 0px; overflow-y: hidden; padding-top: 5px; padding-bottom: 5px; margin: 0px; }
.latexinline { white-space: nowrap }.code { white-space: nowrap }pre, code, kbd, samp, tt{ font-family:'Blog Mono',monospace; }ul, ol { list-style-position: inside; padding-left: 0; }</style></head><body><div class='container'><h2><a id=discriminant-and-resultant href='#discriminant-and-resultant'> § </a> <a href=#discriminant-and-resultant>Discriminant and Resultant</a></h2>
I had always seen the definition of a discriminant of a polynomial <span class='latexinline'>p(x)</span> as:
<div class='latexblock'>
Disc(p(x)) \equiv a_n^{(2n - n)} \prod_{i< j} (r_i - r_j)^2
</div>
While it is clear <i>why</i> this tracks if a polynomial has repeated roots
or not, I could never motivate to myself or remember this definition.
I learnt that in fact, this comes from a more general object, the <b>resultant</b>
of two polynomials <span class='latexinline'>P(x), Q(x)</span>, which provides a new polynomial <span class='latexinline'>Res(P(x), Q(x)</span>
which is zero iff <span class='latexinline'>P, Q</span> share a common root. Then, the discriminant is
defined as the resultant of a polynomial and its derivative. This makes far more
sense:
<ul><li> If a polynomial has a repeated root <span class='latexinline'>r</span>, then its factorization will
  be of the form <span class='latexinline'>p(x) = (x - r)^2 q(x)</span>. The derivative of the polynomial 
  will have an <span class='latexinline'>(x-r)</span> term that can be factored out. </li></ul>
<ul><li> On the contrary, if a polynomial only has a root of degree 1, then the
  factorization will be <span class='latexinline'>p(x) = (x - r) q(x)</span>, where <span class='latexinline'>q(x)</span> is not divisible by <span class='latexinline'>(x-r)</span>.
  Then, the derivative will be <span class='latexinline'>p'(x) = 1 \cdot q(x) + (x - r) q'(x)</span>. We cannot take <span class='latexinline'>(x - r)</span> common
   from this, since <span class='latexinline'>q(x)</span> is not divisible by <span class='latexinline'>(x-r)</span>.</li></ul>
This cleared up a lot of the mystery for me.
<h4><a id=how-did-i-run-into-this-elimination-theory href='#how-did-i-run-into-this-elimination-theory'> § </a> How did I run into this? Elimination theory.</h4>
I was trying to learn how elimination theory works: Given a variety
<span class='latexinline'>V = \{ (x, y) : Z(x, y) = 0 \}</span>, how does one find a rational parametrization
<span class='latexinline'>(p(t), q(t))</span> such that  <span class='latexinline'>Z(p(t), q(t)) = 0</span>, and <span class='latexinline'>p(t), q(t)</span> are
rational functions? That is, how do we find a rational parametrization of the
locus of a polynomial <span class='latexinline'>Z(x, y)</span>? The answer is: use resultants! 
<ul><li> We have two univariate polynomials <span class='latexinline'>p(a; x), p(b; x)</span>, where the notation 
  <span class='latexinline'>p(a; x)</span> means that we have a polynomial <span class='latexinline'>p(a; x) \equiv \sum_i a[i] x^i</span>.
  The resultant isa polynomial <span class='latexinline'>Res(a; b)</span> which is equal to <span class='latexinline'>0</span> when
  <span class='latexinline'>p(a; x)</span> and <span class='latexinline'>p(b; x)</span> share a common root.</li></ul>
<ul><li> We can use this to eliminate variables. We can treat a bivariate polynomial <span class='latexinline'>p(x, y)</span>
  as a univariate polynomial <span class='latexinline'>p'(y)</span> over the ring <span class='latexinline'>R[X]</span>. This way, given two
  bivariate polynomial <span class='latexinline'>p(a; x, y)</span>, <span class='latexinline'>q(b; x, y)</span>, we can compute their resultant,
  giving us conditions to detect for which values of <span class='latexinline'>a, b, x</span>, there exists
  a common <span class='latexinline'>y</span> such that <span class='latexinline'>p(a; x, y)</span> and <span class='latexinline'>(q, x, y)</span> share a root. If <span class='latexinline'>(a, b)</span>
  are constants, then we get a polynomial <span class='latexinline'>Res(x)</span> that tracks whether <span class='latexinline'>p(a; x, y)</span>
  and <span class='latexinline'>q(a; x, y)</span> share a root.</li></ul>
<ul><li> We can treat the implicit equation above as two equations, <span class='latexinline'>x - p(t) = 0</span>, 
  <span class='latexinline'>y - q(t) = 0</span>. We can apply the method of resultants to project out <span class='latexinline'>t</span>
  from the equations.</li></ul>
<h4><a id=5-minute-intro-to-elimination-theory href='#5-minute-intro-to-elimination-theory'> § </a> 5 minute intro to elimination theory.</h4>
Recall that when we have a linear system <span class='latexinline'>Ax = 0</span>, the system has a non-trivial
solution iff <span class='latexinline'>|A| = 0</span>. Formally: <span class='latexinline'>x \neq 0 \iff |A| = 0</span>. Also, the
ratio of solutions is given by:
<div class='latexblock'>x_i / x_j = (-1)^{i+j} |A_i|/|A_j|</div>
If we have two polynomials <span class='latexinline'>p(a; x) = a_0 + a_1 x + a_2 x^2</span>, and
<span class='latexinline'>q(b; x) = b_0 + b_1x + b_2 x^2</span>, then the system <span class='latexinline'>p(a; x)</span>, <span class='latexinline'>q(b; x)</span> has
a simeltaneous zero iff:
<div class='latexblock'>
\begin{align*}
&\begin{bmatrix}
a_2 & a_1 & a_0 & 0 \\
0 & a_2 & a_1 & a_0 \\
b_2 & b_1 & b_0 & 0\\
0 & b_2 & b_1 & b_0\\
\end{bmatrix}
\begin{bmatrix}                                             
1 \\ x \\ x^2 \\ x^3
\end{bmatrix}
= 0 \\
&A x = 0
\end{align*}
</div>
<h4><a id=big-idea href='#big-idea'> § </a> Big idea</h4>
The matrix is setup in such a way that any solution vector <span class='latexinline'>v</span> such that
<span class='latexinline'>Qv = 0</span> will be of the form <span class='latexinline'>v = (\alpha^3, \alpha^2, \alpha, 1)</span>. That is,
the solution vector is a <i>polynomial</i>, such that <span class='latexinline'>Qv = 0</span>. Since <span class='latexinline'>Qv = 0</span>,
we have that <span class='latexinline'>a_2 \alpha^2 + a_1 \alpha + a_0 = 0</span>, and <span class='latexinline'>b_2 \alpha^2 + b_1 \alpha + b_0 = 0</span>.
<h4><a id=proof href='#proof'> § </a> Proof</h4>
<ul><li> <b>Necessity</b> is clear. If we have some non trivial vector <span class='latexinline'>v \neq 0</span> such that
  <span class='latexinline'>Qv = 0</span>, then we need <span class='latexinline'>|Q| = 0</span>.</li></ul>
<ul><li> <b>Sufficiency</b>: Since <span class='latexinline'>|Q| = 0</span>, there is some vector <span class='latexinline'>v = (w, x, y, z)</span>
  such that <span class='latexinline'>Qv = 0</span>. 
  We need to show that this <span class='latexinline'>v</span> is non-trivial. If the polynomials <span class='latexinline'>p(a;x)</span>,
  <span class='latexinline'>q(b;x)</span> are not equal, then we have that the rows which have coefficients
  from <span class='latexinline'>p</span> and <span class='latexinline'>q</span> are linearly independent. So, the pair of rows <span class='latexinline'>(1, 3)</span>,
  and the pair <span class='latexinline'>(2, 4)</span> are linearly independent. This means that
  the linear system:</li></ul>
<div class='latexblock'>
a_2 w + a_1 x + a_0 y = 0 \\
b_2 w + a_1 x + a_0 y = 0 \\
</div>
Similarly:
<div class='latexblock'>
a_2 x + a_1 y + a_0 z = 0 \\
b_2 x + a_1 y + a_0 z = 0 \\
</div>
Since the coefficients of the two systems are the same, we must have that
<span class='latexinline'>(w, x, y)</span> and <span class='latexinline'>(x, y, z)</span> are linearly dependent. That is:
<div class='latexblock'>
(w, x, y) = \alpha (x, y, z) \\
w = \alpha x = \alpha^2 y = \alpha^3 z \\
</div>
We can take <span class='latexinline'>z = 1</span> arbitrarily, giving us a vector of the form
<span class='latexinline'>(w, x, y, z) = (\alpha^3, \alpha^2, \alpha, 1)</span>, which is the structure
of the solution we are looking for!
<h4><a id=references href='#references'> § </a> References</h4>
<ul><li> <a href=http://www.cs.cmu.edu/~me/811/notes/>CMU lectures on Math Fundamentals for Robotics</a></li></ul>
</container></body></html>